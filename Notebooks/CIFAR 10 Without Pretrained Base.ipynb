{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "occasional-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt, pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "employed-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "cf10 = keras.datasets.cifar10\n",
    "(train_X, train_Y), (test_X, test_Y) = cf10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "tracked-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - (42500, 32, 32, 3)\n",
      "Validation Data - (7500, 32, 32, 3)\n",
      "Testing Data - (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#splitting training data into 2 sets\n",
    "#training and validation\n",
    "#stratify maintains class distribution ratio\n",
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.15, stratify=train_Y, random_state=10)\n",
    "\n",
    "#printing data shape\n",
    "print(f'Training Data - {train_X.shape}')\n",
    "print(f'Validation Data - {val_X.shape}')\n",
    "print(f'Testing Data - {test_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "overall-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class labels\n",
    "labels = {0:'Airplane',\n",
    "         1:'Automobile',\n",
    "         2:'Bird',\n",
    "         3:'Cat',\n",
    "         4:'Deer',\n",
    "         5:'Dog',\n",
    "         6:'Frog',\n",
    "         7:'Horse',\n",
    "         8:'Ship',\n",
    "         9:'Truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "distinct-complexity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label - Frog\n"
     ]
    }
   ],
   "source": [
    "#checking data\n",
    "plt.figure()\n",
    "plt.imshow(train_X[0])\n",
    "plt.show()\n",
    "print(f'Image Label - {labels[train_Y[0][0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "underlying-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating network\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    layers.Input(shape=[32,32,3]),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=7, activation='relu', padding='same', strides=2),\n",
    "    layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    \n",
    "    #stage 1\n",
    "    layers.Conv2D(filters=64, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    #stage 2\n",
    "    layers.Conv2D(filters=128, kernel_size=1, activation='relu', padding='same', strides=2),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=128, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    #stage 3\n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same', strides=2),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=256, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=1024, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    #stage 4\n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same', strides=2),\n",
    "    layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=2048, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=2048, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    layers.Conv2D(filters=512, kernel_size=1, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=512, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=2048, kernel_size=1, activation='relu', padding='same'),\n",
    "    \n",
    "    #classification layers\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(units=1024, activation='relu'), \n",
    "    layers.Dense(units=10, activation='sigmoid'), #equal to num classes\n",
    "    layers.Softmax() #to convert vector outputs to class probabilities\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "weekly-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model\n",
    "model.compile(\n",
    "    optimizer= 'adam',\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), #use this loss when labels are integer values\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#callbacks\n",
    "#---------\n",
    "\n",
    "#this stops training if validation accuracy dosent improve by 1% in 15 epochs\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=30, min_delta=0.01, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42500 samples, validate on 7500 samples\n",
      "Epoch 1/200\n",
      "42500/42500 [==============================] - 19s 456us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/200\n",
      "42500/42500 [==============================] - 14s 325us/sample - loss: 2.3026 - accuracy: 0.0952 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/200\n",
      "42500/42500 [==============================] - 14s 325us/sample - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/200\n",
      "42500/42500 [==============================] - 14s 326us/sample - loss: 2.3026 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/200\n",
      "42500/42500 [==============================] - 14s 327us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/200\n",
      "42500/42500 [==============================] - 14s 328us/sample - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/200\n",
      "42500/42500 [==============================] - 14s 326us/sample - loss: 2.3026 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "42500/42500 [==============================] - 14s 327us/sample - loss: 2.3026 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/200\n",
      "42500/42500 [==============================] - 14s 329us/sample - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/200\n",
      "42500/42500 [==============================] - 14s 325us/sample - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "42500/42500 [==============================] - 14s 320us/sample - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/200\n",
      "42500/42500 [==============================] - 14s 320us/sample - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0963 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 31/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 32/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 33/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 34/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 35/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0948 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 36/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 37/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0948 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 38/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 39/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 40/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 41/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0961 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 42/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 43/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 44/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 45/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 46/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 47/200\n",
      "42500/42500 [==============================] - 14s 321us/sample - loss: 2.3026 - accuracy: 0.0952 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 48/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 49/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 50/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 51/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 52/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 53/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 55/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 56/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 57/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0948 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 58/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 59/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 60/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 61/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 62/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 63/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 64/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 65/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 66/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 67/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 68/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 69/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0954 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 70/200\n",
      "42500/42500 [==============================] - 14s 322us/sample - loss: 2.3026 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 71/200\n",
      "42500/42500 [==============================] - 14s 324us/sample - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 72/200\n",
      "42500/42500 [==============================] - 14s 323us/sample - loss: 2.3026 - accuracy: 0.0953 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 73/200\n",
      " 9900/42500 [=====>........................] - ETA: 10s - loss: 2.3026 - accuracy: 0.1012"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "history = model.fit(\n",
    "    train_X, train_Y,\n",
    "    validation_data= (val_X, val_Y),\n",
    "    batch_size=300,\n",
    "    epochs=200,\n",
    "    #callbacks =[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curves\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();\n",
    "print(\"Minimum validation loss: {}\".format(history_df['val_loss'].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "preds = model.predict(test_X)\n",
    "\n",
    "#checking random prediction\n",
    "plt.figure()\n",
    "plt.imshow(test_X[5])\n",
    "plt.show()\n",
    "print(f'The label is - {labels[test_Y[5][0]]}')\n",
    "print(f'Model predicted - {labels[np.argmax(preds[5])]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model performance\n",
    "model.evaluate(test_X, test_Y,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
